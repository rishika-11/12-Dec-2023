# -*- coding: utf-8 -*-
"""Epileptic Seizure Recognition code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YuSjj4J_J3FRMhgmJyd9044-3QO07e-C
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sn

ESR = pd.read_csv("Epileptic Seizure Recognition.csv")

"""#    DATA PREPROCESSING


"""

# Display the first few rows of the dataset
ESR.head()

cols = ESR.columns   # Extract column names
tgt = ESR.y          # Extract the target variable 'y'
tgt[tgt>1]=0         # Convert values greater than 1 to 0
ax = sn.countplot(tgt,label="Count")     # Plot the count of each class
non_seizure, seizure = tgt.value_counts()
print('The number of trials for the non-seizure class is:', non_seizure)
print('The number of trials for the seizure class is:', seizure)

# Check for missing values
ESR.isnull().sum()

# Display information about the dataset
ESR.info()

# Display descriptive statistics of the dataset
ESR.describe()

# Extract features (X) and target variable (y)
X = ESR.iloc[:,1:179].values
X.shape

# Visualize a subset of samples for each class
plt.subplot(511)
plt.plot(X[1,:])
plt.title('Classes')
plt.ylabel('uV')
plt.subplot(512)
plt.plot(X[7,:])
plt.subplot(513)
plt.plot(X[12,:])
plt.subplot(514)
plt.plot(X[0,:])
plt.subplot(515)
plt.plot(X[2,:])
plt.xlabel('Samples')

y = ESR.iloc[:,179].values
y

# Convert target variable values greater than 1 to 0
y[y>1]=0
y

# Split the dataset into training and testing sets
from sklearn.model_selection import train_test_split, cross_val_score
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

# Standardize the features
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# MODEL TRAINING AND EVALUATION"""

# Train a Logistic Regression model
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression()
clf.fit(X_train, y_train)
y_pred_log_reg = clf.predict(X_test)
acc_log_reg = round(clf.score(X_train, y_train) * 100, 2)
print (str(acc_log_reg) + ' %')

# Train an SVM model
from sklearn.svm import SVC
clf = SVC()
clf.fit(X_train, y_train)
y_pred_svc = clf.predict(X_test)
acc_svc = round(clf.score(X_train, y_train) * 100, 2)
print (str(acc_svc) + '%')

# Train a Linear SVM model
from sklearn.svm import SVC, LinearSVC
clf = LinearSVC()
clf.fit(X_train, y_train)
y_pred_linear_svc = clf.predict(X_test)
acc_linear_svc = round(clf.score(X_train, y_train) * 100, 2)
print (str(acc_linear_svc) + '%')

# Train a K-Nearest Neighbors model
from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier()
clf.fit(X_train, y_train)
y_pred_knn = clf.predict(X_test)
acc_knn = round(clf.score(X_train, y_train) * 100, 2)
print (str(acc_knn)+'%')

# Train a Navie Bayes model
from sklearn.naive_bayes import GaussianNB
clf = GaussianNB()
clf.fit(X_train, y_train)
y_pred_gnb = clf.predict(X_test)
acc_gnb = round(clf.score(X_train, y_train) * 100, 2)
print (str(acc_gnb) + '%')

# Apply Principal Component Analysis (PCA)
from sklearn.decomposition import PCA
pca = PCA()
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)
acc_PCA = round(pca.score(X_train, y_train) )
print (str(acc_PCA) + '%')

#Importing keras libraries and packages
import keras
from keras.models import Sequential
from keras.layers import Dense

"""# Build an Artificial Neural Network (ANN) using Keras

"""

classifier = Sequential()

classifier.add(Dense(activation="relu", input_dim=178, units=80, kernel_initializer="uniform"))

classifier.add(Dense(activation="relu", units=80, kernel_initializer="uniform"))

classifier.add(Dense(activation="sigmoid", units=1, kernel_initializer="uniform"))

classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

#Fitting the ANN to the training set
classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)

"""# Result Visualization"""

# Predicting the Test set results
y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)
# Evaluate the ANN
acc_ANN = round(clf.score(X_train, y_train) * 100, 2)
print (str(acc_ANN) + '%')

# Apply PCA to the training set
from sklearn.decomposition import PCA
pca = PCA()
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)
acc_PCA = round(pca.score(X_train, y_train) )
print (str(acc_PCA) + '%')

# Create a DataFrame to compare model scores
models = pd.DataFrame({
    'Model': ['Logistic Regression', 'Support Vector Machines','ANN',
              'KNN', 'Naive Bayes', 'Principal Component Analysis'],

    'Score': [acc_log_reg, acc_svc,acc_ANN ,
              acc_knn, acc_gnb,acc_PCA ]
    })

models.sort_values(by='Score', ascending=False)